
 <!DOCTYPE HTML>
<html lang="zh-cn">
<head>
  <meta charset="UTF-8">
  
    <title>Build Hadoop Cluster in One Computer | lunge博客</title>
    <meta name="viewport" content="width=device-width, initial-scale=1,user-scalable=no">
    
    <meta name="author" content="张伦">
    

    
    <meta name="description" content="If you are hadoop novice, I strongly suggest you beginning your study from single node building,you can learn from this website, after you having finshed build one single node, then you can reading m">
<meta property="og:type" content="article">
<meta property="og:title" content="Build Hadoop Cluster in One Computer">
<meta property="og:url" content="https://mrzhangboss.github.io/2018/10/14/BuildHadoopClusterinOneComputer/index.html">
<meta property="og:site_name" content="lunge博客">
<meta property="og:description" content="If you are hadoop novice, I strongly suggest you beginning your study from single node building,you can learn from this website, after you having finshed build one single node, then you can reading m">
<meta property="og:image" content="https://mrzhangboss.github.io/images/vm-create1.png">
<meta property="og:image" content="https://mrzhangboss.github.io/images/vm-net-adapter.png">
<meta property="og:updated_time" content="2018-10-22T13:58:21.199Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Build Hadoop Cluster in One Computer">
<meta name="twitter:description" content="If you are hadoop novice, I strongly suggest you beginning your study from single node building,you can learn from this website, after you having finshed build one single node, then you can reading m">
<meta name="twitter:image" content="https://mrzhangboss.github.io/images/vm-create1.png">
<meta name="twitter:creator" content="@mrzhangboss">

    
    <link rel="alternative" href="/atom.xml" title="lunge博客" type="application/atom+xml">
    
    
    <link rel="icon" href="/img/wx2.png">
    
    
    <link rel="apple-touch-icon" href="/img/wx2.png">
    <link rel="apple-touch-icon-precomposed" href="/img/wx2.png">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      
<div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/wx2.png" alt="lunge博客" title="lunge博客"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="lunge博客">lunge博客</a></h1>
				<h2 class="blog-motto"></h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="菜单">
			</a></div>
			<nav class="animated">
				<ul>
					<ul>
					 
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
						<li><a href="/about">About</a></li>
					
					<li>
 					
					<form class="search" action="/search/index.html" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="search" id="search" autocomplete="off" name="q" maxlength="20" placeholder="搜索" />
					</form>
					
					</li>
				</ul>
			</nav>			
</div>
    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
  
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/10/14/BuildHadoopClusterinOneComputer/" title="Build Hadoop Cluster in One Computer" itemprop="url">Build Hadoop Cluster in One Computer</a>
  </h1>
  <p class="article-author">By
       
		<a href="/about" title="张伦" target="_blank" itemprop="author">张伦</a>
		
  <p class="article-time">
    <time datetime="2018-10-13T16:00:00.000Z" itemprop="datePublished"> 发表于 2018-10-14</time>
    
  </p>
</header>
	<div class="article-content">
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">文章目录</strong>
		
			<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Clusters-On-VirtualBox"><span class="toc-number">3.</span> <span class="toc-text">Clusters On VirtualBox</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Build-Ubuntu-VMS"><span class="toc-number">3.1.</span> <span class="toc-text">Build Ubuntu VMS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">3.2.</span> <span class="toc-text">Conclusion</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Clusters-On-Docker"><span class="toc-number">4.</span> <span class="toc-text">Clusters On Docker</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion-1"><span class="toc-number">5.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-number">6.</span> <span class="toc-text">References</span></a></li></ol>
		
		</div>
		
		<blockquote>
<p>If you are hadoop novice, I strongly suggest you beginning your study from single node building,you can learn from this <a href="https://www.tutorialspoint.com/hadoop/" target="_blank" rel="external">website</a>, after you having finshed build one single node, then you can reading my blog to learn how to run a N-node clusters just in your computer.</p>
</blockquote>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>This blog is introduce using one computer to build a N-node clusters.I suggest you use ubuntu to build. You can also use Windows, but you’d better install virtualbox to install one desktop ubuntu  as your base server.In this blog, we will try two different way to build hadoop clusters in one computer.</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Before you start learning, you can download these required softwares from Intelnet.</p>
<ul>
<li>JDK8(optional)</li>
</ul>
<p>we can also install it by apt tool, but may be slow in China.So you’d better download it from website.</p>
<p><a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" target="_blank" rel="external">https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a></p>
<p>choose “jdk-8u181-linux-x64.tar.gz” to download.You can alse install in your master computer later, you can read from this <a href="https://websiteforstudents.com/how-to-install-oracle-java-jdk8-on-ubuntu-16-04-17-10-18-04-desktops/" target="_blank" rel="external">blog</a></p>
<ul>
<li>Hadoop(2.85)</li>
</ul>
<p>I choose latest 2.85 version, you can download from this website.</p>
<p><a href="https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.8.5/hadoop-2.8.5-src.tar.gz" target="_blank" rel="external">https://www.apache.org/dyn/closer.cgi/hadoop/common/hadoop-2.8.5/hadoop-2.8.5-src.tar.gz</a></p>
<ul>
<li>Ubuntu Image</li>
</ul>
<p>In this trip, we choose Ubuntu16.04 server for build clusters.You can use 163 mirrors to speed up your download.</p>
<p><a href="http://mirrors.163.com/ubuntu-releases/16.04.5/ubuntu-16.04.5-server-amd64.iso" target="_blank" rel="external">http://mirrors.163.com/ubuntu-releases/16.04.5/ubuntu-16.04.5-server-amd64.iso</a></p>
<ul>
<li><p>Virtualbox</p>
<p>we need <code>virtualbox</code> to create our clusters. It’s easy for you to install virtualbox in ubuntu. You can read this <a href="https://tecadmin.net/install-oracle-virtualbox-on-ubuntu/" target="_blank" rel="external">article</a> to install virtualbox-5.2</p>
<ul>
<li>Docker</li>
</ul>
</li>
</ul>
<p>we will try use docker build our clusters, it’s easy install in ubuntu.The install tutorials is <a href="https://docs.docker.com/install/linux/docker-ce/ubuntu/#uninstall-old-versions" target="_blank" rel="external">https://docs.docker.com/install/linux/docker-ce/ubuntu/#uninstall-old-versions</a></p>
<h2 id="Clusters-On-VirtualBox"><a href="#Clusters-On-VirtualBox" class="headerlink" title="Clusters On VirtualBox"></a>Clusters On VirtualBox</h2><p>Now I assuming you’re working on a ubuntu16.04 desktop OS.Now let’s begining our trip.</p>
<p>First,let’s init a master, after we install required software in master, we can use virtualbox <code>clone</code> function to easy to build slave.</p>
<h3 id="Build-Ubuntu-VMS"><a href="#Build-Ubuntu-VMS" class="headerlink" title="Build Ubuntu VMS"></a>Build Ubuntu VMS</h3><ul>
<li>new a machine named master</li>
</ul>
<p><img src="/images/vm-create1.png" alt=""></p>
<ul>
<li>Choose 2G RAM, VDI </li>
</ul>
<p>then run this image, load the iso file you downloaded.Pay attention to make true install ssh server( Or you can install after installing os by <code>apt</code>)</p>
<blockquote>
<p>Before we start install hadoop and java skd, let me tell you something about the internet require.</p>
</blockquote>
<p>For our clusters runing, we need a connected internet between master and slaves.If we have many computers, it’s simple, we just need they both have public IP or private IP in one LAN.But if we just in one computer, how can we have independent IP for our master and slaves.</p>
<p>This is why we install <code>virtualbox</code>, <code>virtualbox</code> provide our independent computers in just one computer.Moreover, it can provide a simulate NIC for each computer.By using that, each computer can have they own private IP in LAN. </p>
<p>So the key our cluster running is the <code>bridge</code></p>
<p><img src="/images/vm-net-adapter.png" alt=""></p>
<p>we need choose the <code>bridged adapter</code> to make master and slaves just in same LAN.Pay attention to make true you need choose your real NIC.In ubuntu you just run <code>ifconfig</code> and find out have one line <code>inet addr:192.168.1.12</code> .Usually it’s <code>eth0</code> in ubuntu.</p>
<p>When you have finished OS installment.You can login in and start installing hadoop clusters.</p>
<blockquote>
<p>Step 1. Configure Static IP</p>
</blockquote>
<p>In your virtual machine, your IP is changeable when reboot.Because ubuntu use DHCP for init your IP from gateway.We need make true our  master and slaves have changeless IP to protect their connection.</p>
<p>To do this, first you need make true your installment is ok. Try <code>ping  baidu.com</code> to check you connected Internet or not.Then we need know our gateway address.Try run <code>route</code> in shell, you can find a table, in the row <code>Gateway</code>, you can find one or more static IP like <code>192.168.0.1</code> , this is your gateway.Now we open our internet settings.</p>
<pre><code>cat /etc/network/interfaces    
</code></pre><p>you can see something like this</p>
<pre><code>auto eth0
iface eth0 inet dhcp
</code></pre><p><code>eth0</code> is your NIC(yours maybe different). and we use <code>dhcp</code> to get IP. Now we need change it to static.</p>
<pre><code>auto eth0
iface eth0 inet static
address 192.168.0.105
netmask 255.255.255.0
gateway 192.168.0.1
</code></pre><p>PS: make true, you need change the <code>eth0</code> and <code>gateway</code> IP to yours.The address <code>IP</code> must be subnet of gateway under the control of netmast.eg, you can’t set you ip address to 10.1.1.1 if your gateway is 192.168.0.1.The easiest way is set by <code>dhcp</code> format.And just change the last number.If you still can’t connect the Internet.Try add one line <code>dns-nameservers 8.8.8.8</code> .</p>
<pre><code>ifdown eth0
ifup  eth0
</code></pre><p>now run upper commands in your vm(<code>eth0</code> need your NIC name).If run <code>ifconfig</code> again, you can see our IP address chage to <code>192.168.0.105</code> now!</p>
<blockquote>
<p>Step 2. Add Hostname alias</p>
</blockquote>
<p>Becase hadoop need hostname to identify their ID, so now we add <code>Hostname-IP</code> pair to smooth our connection.</p>
<p>Just edit <code>/etc/hosts/</code> and add three line below</p>
<pre><code>192.168.0.105 master
192.168.0.104 slave1
192.168.0.103 slave2
</code></pre><blockquote>
<p>Step 3. Make SSH Login</p>
</blockquote>
<p>Becase hadoop need login by root with <code>SSH</code> , so we need make <code>root</code> can login in in ubuntu.Open <code>/etc/ssh/sshd_config</code> and change line <code>PermitRootLogin prohibit-password</code> to <code>PermitRootLogin yes</code>, then <code>service ssh restart</code> .</p>
<p>Also you need use your <code>sudo</code> to set password for root</p>
<pre><code>sudo passwd root
</code></pre><p>now check you can login in with <code>root</code></p>
<pre><code>ssh root@127.0.0.1
</code></pre><blockquote>
<p>Step 4. Set Hadoop Env</p>
</blockquote>
<p>First, we need install <code>JDK</code> for hadoop, now back to your host computer. And use <code>scp</code> to upload <code>JDK</code> to vm.You can add below to <code>/etc/hosts</code> in your host machine.</p>
<pre><code>192.168.0.105 master
192.168.0.104 slave1
192.168.0.103 slave2
</code></pre><p>then you can easy upload your <code>JDK</code> and <code>Hadoop</code> to your vm(you need unpack this tar.gz file first)</p>
<pre><code>scp -r /path/your/jdk root@master:/usr/lib/jvm/java-8-oracle

scp -r /path/your/hadooproot@master:/usr/local/hadoop
</code></pre><p>PS: you can also install <code>Java8</code> by <code>apt</code></p>
<p>Now, we installed <code>JDK</code> and <code>Hadoop</code> in our VM.Then we back to VM and initialize our <code>Hadoop</code>.</p>
<ul>
<li>Set JDK Home</li>
</ul>
<p>edit <code>hadoop-env.sh</code>(in <code>/usr/local/hadoop/etc/hadoop/</code>) file add <code>export JAVA_HOME=/usr/lib/jvm/java-8-oracle</code> to tell <code>Hadoop</code> JDK local address.</p>
<ul>
<li>Set Core IP</li>
</ul>
<p>We need a boss to handle all employer.So edit <code>core-site.xml</code>(in <code>/usr/local/hadoop/etc/hadoop/</code>) and add a property in <code>configuration</code></p>
<pre><code>&lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://master:9000/&lt;/value&gt;
&lt;/property&gt;
</code></pre><p>each cluster will send heartbeat to <code>master:9000</code>.</p>
<ul>
<li>Set <code>HDFS</code> replication and file dir</li>
</ul>
<p>The hadoop basement is <code>HDFS</code>, edit <code>hdfs-site.xml</code> and add three property </p>
<pre><code>&lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;

 &lt;property&gt;
        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
        &lt;value&gt;file:///root/hdfs/namenode&lt;/value&gt;

    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
        &lt;value&gt;file:///root/hdfs/datanode&lt;/value&gt;

    &lt;/property&gt;
</code></pre><p>The <code>dfs.replication</code> meaning the backups of <code>HDFS</code>, <code>dfs.namenode.name.dir</code> and <code>dfs.datanode.data.dir</code> is optional.If you not set this, it will store under <code>/tmp</code> (when reboot ,it will delete).</p>
<ul>
<li>Set <code>Yarn</code> for <code>MapReduce</code></li>
</ul>
<p>In hadoop2, we use <code>Yarn</code> to manage our <code>MapReduce</code>, run <code>cp mapred-site.xml.template mapred-site.xml</code> and then add property to set <code>Yarn</code> as our <code>MapReduce</code> framework</p>
<pre><code>&lt;property&gt;
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
    &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
</code></pre><p>and we also need tell <code>yarn</code> the <code>master</code> of the clusters and our need open <code>MapReduce</code> <code>Shuffle</code> Fuction effective our <code>MapReduce</code>, edit <code>yarn-site.xml</code>, and add two property</p>
<pre><code>&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
    &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
    &lt;value&gt;master&lt;/value&gt;
&lt;/property&gt;
</code></pre><p><code>yarn.nodemanager.aux-services</code> open <code>shuffle</code>, and <code>yarn.resourcemanager.hostname</code> set <code>ResourceManager</code> hostname.</p>
<hr>
<p>Now we complete the base <code>Hadoop</code> settings, now we can try run <code>hadoop</code> on <code>master</code></p>
<pre><code>cd /usr/local/hadoop/
bin/hadoop namenode -format
sbin/start-dfs.sh
</code></pre><p>We try format our namenode, and start dfs server, now run <code>jps</code>, you  can see <code>NameNode</code> and <code>SecondaryNameNode</code> server started.</p>
<p>Now we try start <code>Yarn</code> to start <code>MapReduce FrameWork</code>.</p>
<pre><code>sbin/start-yarn.sh
</code></pre><p>Now, rerun <code>jps</code>, you can see <code>ResourceManager</code> running.You can also try <code>netstat -tuplen|grep 8088</code>, you will find the <code>ResourceManager</code> open some tcp port like 8080,8031,8033,etc.And the <code>8088</code> is the website of  managing clusters.You can open <a href="http://master:8088" target="_blank" rel="external">http://master:8088</a> to see the <code>clusters</code> status.Now you can only see blank node in clusters, for we have not started one slave yet.</p>
<p>Congratulation, our master is starting, in the running, we need input our password when start, after complete all slave building, we can use ssh-key to autologin.</p>
<blockquote>
<p>Now let’s build our slaves.</p>
</blockquote>
<p>Use <code>virtualbox</code> clone function, we clone <code>master</code> to a new VM named <code>slave1</code>.</p>
<p>Because we clone every thing to the <code>slave1</code>, so we need close <code>master</code> and goto <code>slave1</code> change  its hostname and static IP make it to be a <code>slave</code></p>
<p>First we need do is rename the VM,edit <code>/etc/hostname</code> change it to <code>slave1</code>,  then we need do is setting <code>slave1</code> Static IP, we do like upper.Just replace IP to <code>192.168.0.104</code>, and then we reboot and start <code>master</code> and <code>slave1</code> at meatime.</p>
<p>Now let’s check master to start our <code>slave1</code>, in our <code>master</code> VM, we edit <code>/usr/local/hadoop/etc/hadoop/slaves</code> file, and one line </p>
<pre><code>slave1
</code></pre><p>and make true you have add slaves’ hostname alias in <code>master</code> VM.<br>Then we try start our <code>Cluster</code></p>
<pre><code> cd /usr/local/hadoop
bin/hadoop datanode -format
sbin/start-dfs.sh &amp;&amp; sbin/start-yarn.sh
</code></pre><p>After running these command, check <a href="http://master:8088" target="_blank" rel="external">http://master:8088</a>  to find the master have one slave online named <code>slave1</code>.</p>
<p>PS: Now you can generate ssh-key for your login in slaves, just run <code>ssh-keygen -t rsa &amp;&amp; ssh-copy-id slave1</code>, you don’t need input your password to start your clusters.</p>
<p>Now we have one node clusters, if you want more, you can add more slaves repeatting upper produce.</p>
<p>After you build your N-Clusters , you can now run those commands to check the hadoop working or not.</p>
<pre><code># create input files

mkdir input
echo &quot;Hello Docker&quot; &gt;input/file2.txt
echo &quot;Hello Hadoop&quot; &gt;input/file1.txt

# create input directory on HDFS
hadoop fs -mkdir -p input

# put input files to HDFS
hdfs dfs -put ./input/* input


# run wordcount 
cd /usr/local/hadoop/bin
hadoop jar ../share/hadoop/mapreduce/sources/hadoop-mapreduce-examples-*-sources.jar org.apache.hadoop.examples.WordCount input output

# print the input files
echo -e &quot;\ninput file1.txt:&quot;
hdfs dfs -cat input/file1.txt

echo -e &quot;\ninput file2.txt:&quot;
hdfs dfs -cat input/file2.txt

# print the output of wordcount
echo -e &quot;\nwordcount output:&quot;
hdfs dfs -cat output/part-r-00000
</code></pre><p>PS: By the way, if you want to running this clusters for a long time, you can try use <code>vboxmanage</code> to manage the vm. You can simple use <code>vboxmanage startvm master --type headless</code> to start master background(change <code>master</code> to other VM name can start them too)</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>The difficult of build a clusters in virtualbox is know how master and slaves connecting each other.If you set a right network, it’s easy to running the cluster.But there’re some problem in <code>virtualbox</code>, we can’t share our network in the host LAN with virtualbox <code>bridge</code>. So we will introduce you build clusters in <code>Docker</code> and we can run our clusters in a swarm clusters in a real envirment.</p>
<h2 id="Clusters-On-Docker"><a href="#Clusters-On-Docker" class="headerlink" title="Clusters On Docker"></a>Clusters On Docker</h2><p>Building clusters is much easily in docker, for docker provide a easy network bride in sigle computer or in a swarm clusters.</p>
<p>we use <code>kiwenlau/hadoop:1.0</code> image to our test(which hadoop version is 2.7).Just run</p>
<pre><code>sudo docker pull kiwenlau/hadoop:1.0
</code></pre><p>After few minutes, we can have a hadoop images, now we need set our private LAN Net just use this(If you want to run a swarm clusters above many computers, just change <code>bridge</code> to <code>overlay</code>, powerful, isn’t it)</p>
<pre><code>sudo docker network create --driver=bridge hadoop
</code></pre><p>Now let start our master server</p>
<pre><code>sudo docker run -itd \
                --net=hadoop \
                -p 50070:50070 \
                -p 8088:8088 \
                --name hadoop-master \
                --hostname hadoop-master \
                kiwenlau/hadoop:1.0 &amp;&gt; /dev/null
</code></pre><p>In the command, we set the master hostname to <code>hadoop-master</code>.and we needn’t change <code>/etc/hosts</code> to add it like in <code>virtualbox</code>, docker will do it for us.</p>
<p>Now we start our slaves</p>
<pre><code>sudo docker run -itd \
                --net=hadoop \
                --name hadoop-slave1 \
                --hostname hadoop-slave1 \
                kiwenlau/hadoop:1.0 &amp;&gt; /dev/null

sudo docker run -itd \
                --net=hadoop \
                --name hadoop-slave2 \
                --hostname hadoop-slave2 \
                kiwenlau/hadoop:1.0 &amp;&gt; /dev/null
</code></pre><p>After doing that, we have finshed all softwares build.Now just run<code>sudo docker exec -it hadoop-master bash</code> into <code>master</code>, and then start our clusters <code>bash start-hadoop.sh</code>.</p>
<p>Now you can enjoy your clusters in few minutes, open <a href="http://127.0.0.1:8088/" target="_blank" rel="external">http://127.0.0.1:8088/</a> to see our clusters running happily.</p>
<h2 id="Conclusion-1"><a href="#Conclusion-1" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>After introducing two way to build a hadoop clusters, you will find it’s easy to build a clusters if you know how they work together.In a word, we kind of like using <code>Docker</code> to running hadoop clusters, we can easy move add more <code>Hadoop</code> slaves in just one command.Meantime we can use <code>bridge</code> or <code>overlay</code> network for us building a more safe hadoop clusters.</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p><a href="https://github.com/kiwenlau/hadoop-cluster-docker" target="_blank" rel="external">https://github.com/kiwenlau/hadoop-cluster-docker</a></p>
  
	</div>
		<footer class="article-footer clearfix">
<div class="article-catetags">


  <div class="article-tags">
  
  <span></span> <a href="/tags/big-data-hadoop/">big-data hadoop</a>
  </div>

</div>



	<div class="article-share" id="share">
	
	  <div data-url="https://mrzhangboss.github.io/2018/10/14/BuildHadoopClusterinOneComputer/" data-title="Build Hadoop Cluster in One Computer | lunge博客" data-tsina="5364356330" class="share clearfix">
	  </div>
	
	</div>


</footer>

   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2018/10/20/LearningScalaFromJava/" title="Learning Scala From Java">
  <strong>上一篇：</strong><br/>
  <span>
  Learning Scala From Java</span>
</a>
</div>


<div class="next">
<a href="/2018/10/13/StartingUsingEnglishInMyBlog/"  title="Starting Using English In My Blog">
 <strong>下一篇：</strong><br/> 
 <span>Starting Using English In My Blog
</span>
</a>
</div>

</nav>

	
<section id="comments" class="comment">
	<div class="ds-thread" data-thread-key="2018/10/14/BuildHadoopClusterinOneComputer/" data-title="Build Hadoop Cluster in One Computer" data-url="https://mrzhangboss.github.io/2018/10/14/BuildHadoopClusterinOneComputer/"></div>
</section>




</div>  
      <div class="openaside"><a class="navbutton" href="#" title="显示侧边栏"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">文章目录</strong>
 
 <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Abstract"><span class="toc-number">1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Introduction"><span class="toc-number">2.</span> <span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Clusters-On-VirtualBox"><span class="toc-number">3.</span> <span class="toc-text">Clusters On VirtualBox</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Build-Ubuntu-VMS"><span class="toc-number">3.1.</span> <span class="toc-text">Build Ubuntu VMS</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">3.2.</span> <span class="toc-text">Conclusion</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Clusters-On-Docker"><span class="toc-number">4.</span> <span class="toc-text">Clusters On Docker</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion-1"><span class="toc-number">5.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#References"><span class="toc-number">6.</span> <span class="toc-text">References</span></a></li></ol>
 
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="隐藏侧边栏"></a></div>
<aside class="clearfix">

  

  
<div class="tagslist">
	<p class="asidetitle">标签</p>
		<ul class="clearfix">
		
			
				<li><a href="/tags/summary/" title="summary">summary<sup>13</sup></a></li>
			
		
			
				<li><a href="/tags/programming/" title="programming">programming<sup>12</sup></a></li>
			
		
			
				<li><a href="/tags/software/" title="software">software<sup>8</sup></a></li>
			
		
			
				<li><a href="/tags/python/" title="python">python<sup>8</sup></a></li>
			
		
			
				<li><a href="/tags/mit6-828/" title="mit6.828">mit6.828<sup>7</sup></a></li>
			
		
			
				<li><a href="/tags/HTTP/" title="HTTP">HTTP<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/github/" title="github">github<sup>4</sup></a></li>
			
		
			
				<li><a href="/tags/competition/" title="competition">competition<sup>3</sup></a></li>
			
		
			
				<li><a href="/tags/TDD/" title="TDD">TDD<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/Java/" title="Java">Java<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/big-data/" title="big-data">big-data<sup>2</sup></a></li>
			
		
			
				<li><a href="/tags/software-DL/" title="software, DL">software, DL<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Python3-GIL/" title="Python3, GIL">Python3, GIL<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/transform/" title="transform">transform<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Python3/" title="Python3">Python3<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/big-data-hadoop/" title="big-data hadoop">big-data hadoop<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Hadoop-Spark-Hive-Hbase/" title="Hadoop Spark Hive Hbase">Hadoop Spark Hive Hbase<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/Scala-Java/" title="Scala Java">Scala Java<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/MySQL-ElasticSearch-Python3/" title="MySQL, ElasticSearch, Python3">MySQL, ElasticSearch, Python3<sup>1</sup></a></li>
			
		
			
				<li><a href="/tags/python3/" title="python3">python3<sup>1</sup></a></li>
			
		
		</ul>
</div>


  <div class="linkslist">
  <p class="asidetitle">友情链接</p>
    <ul>
        
          <li>
            
            	<a href="https://segmentfault.com/ " target="_blank" title="一个面向程序员交流分享的新一代社区">segmentfault</a>
            
          </li>
        
    </ul>
</div>

  


  <div class="rsspart">
	<a href="/atom.xml" target="_blank" title="rss">RSS 订阅</a>
</div>

  <div class="weiboshow">
  <p class="asidetitle">新浪微博</p>
    <iframe width="100%" height="119" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=119&fansRow=2&ptype=1&speed=0&skin=9&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=5364356330&verifier=&dpc=1"></iframe>
</div>


</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<section class="info">
		<p> Hello ,I&#39;m zhanglun. <br/>
			This is my blog.</p>
	</section>
	 
	<div class="social-font" class="clearfix">
		
		<a href="http://weibo.com/5364356330" target="_blank" class="icon-weibo" title="微博"></a>
		
		
		<a href="https://github.com/mrzhangboss" target="_blank" class="icon-github" title="github"></a>
		
		
		<a href="http://stackoverflow.com/users/6599843" target="_blank" class="icon-stack-overflow" title="stackoverflow"></a>
		
		
		<a href="https://twitter.com/mrzhangboss" target="_blank" class="icon-twitter" title="twitter"></a>
		
		
		<a href="https://www.facebook.com/100011375031071" target="_blank" class="icon-facebook" title="facebook"></a>
		
		
		
		
		<a href="http://www.zhihu.com/people/zhang-lun-59-53" target="_blank" class="icon-zhihu" title="知乎"></a>
		
		
		
		<a href="mailto:2529450174@qq.com" target="_blank" class="icon-email" title="Email Me"></a>
		
	</div>
			
		

		<p class="copyright">
		Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/wuchong/jacman" target="_blank" title="Jacman">Jacman</a> © 2019 
		
		<a href="/about" target="_blank" title="张伦">张伦</a>
		
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/jquery.qrcode-0.12.0.min.js"></script>

<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
  
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else{
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  c.click(function(){
    ta.css('display', 'block').addClass('fadeIn');
  });
  o.click(function(){
    ta.css('display', 'none');
  });
  $(window).scroll(function(){
    ta.css("top",Math.max(140,320-$(this).scrollTop()));
  });
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina'),
      description = $this.attr('description');
  var html = [
  '<div class="hoverqrcode clearfix"></div>',
  '<a class="overlay" id="qrcode"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="微信"></a>',
  '<a href="http://widget.renren.com/dialog/share?resourceUrl=' + encodedUrl + '&srcUrl=' + encodedUrl + '&title=' + title +'" class="article-share-renren" target="_blank" title="人人"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="微博"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);

  $('.hoverqrcode').hide();

  var myWidth = 0;
  function updatehoverqrcode(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
    var qrsize = myWidth > 1024 ? 200:100;
    var options = {render: 'image', size: qrsize, fill: '#2ca6cb', text: url, radius: 0.5, quiet: 1};
    var p = $('.article-share-qrcode').position();
    $('.hoverqrcode').empty().css('width', qrsize).css('height', qrsize)
                          .css('left', p.left-qrsize/2+20).css('top', p.top-qrsize-10)
                          .qrcode(options);
  };
  $(window).resize(function(){
    $('.hoverqrcode').hide();
  });
  $('.article-share-qrcode').click(function(){
    updatehoverqrcode();
    $('.hoverqrcode').toggle();
  });
  $('.article-share-qrcode').hover(function(){}, function(){
      $('.hoverqrcode').hide();
  });
});   
</script>



<script type="text/javascript">
  var duoshuoQuery = {short_name:"lunge"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
    || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script> 









<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.article-content').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox')) return;
      var alt = this.alt;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'article' + i);
    });
  });
  if($.fancybox){
    $('.fancybox').fancybox();
  }
}); 
</script>



<!-- Analytics Begin -->

<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-80810286-1,UA-80810286-2', 'auto,auto');  
ga('send', 'pageview');
</script>



<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "//hm.baidu.com/hm.js?e6d1f421bbc9962127a50488f9ed37d1";
  var s = document.getElementsByTagName("script")[0]; 
  s.parentNode.insertBefore(hm, s);
})();
</script>



<!-- Analytics End -->

<!-- Totop Begin -->

	<div id="totop">
	<a title="返回顶部"><img src="/img/scrollup.png"/></a>
	</div>
	<script src="/js/totop.js"></script>

<!-- Totop End -->

<!-- MathJax Begin -->
<!-- mathjax config similar to math.stackexchange -->


<!-- MathJax End -->

<!-- Tiny_search Begin -->

<!-- Tiny_search End -->

  </body>
</html>
